{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section must be included at the beginning of each new notebook. Remember to change the app name. \n",
    "# If you're using VirtualBox, change the below to '/home/user/spark-2.1.1-bin-hadoop2.7'\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('zli786-Iteration4').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the dataset\n",
    "df = spark.read.options(header='True', inferSchema='True').csv(\"./dataset1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+---+----+-----+-----+----+----+---+----+----+------+-----+----+---+----+---------+\n",
      "| No|year|month|day|hour|PM2.5| PM10| SO2| NO2| CO|  O3|TEMP|  PRES| DEWP|RAIN| wd|WSPM|  station|\n",
      "+---+----+-----+---+----+-----+-----+----+----+---+----+----+------+-----+----+---+----+---------+\n",
      "|  1|2013|    3|  1|   0|  3.0|  6.0|13.0| 7.0|300|85.0|-2.3|1020.8|-19.7| 0.0|  E| 0.5|Changping|\n",
      "|  2|2013|    3|  1|   1|  3.0|  3.0| 6.0| 6.0|300|85.0|-2.5|1021.3|-19.0| 0.0|ENE| 0.7|Changping|\n",
      "|  3|2013|    3|  1|   2|  3.0|  3.0|22.0|13.0|400|74.0|-3.0|1021.3|-19.9| 0.0|ENE| 0.2|Changping|\n",
      "|  4|2013|    3|  1|   3|  3.0|  6.0|12.0| 8.0|300|81.0|-3.6|1021.8|-19.1| 0.0|NNE| 1.0|Changping|\n",
      "|  5|2013|    3|  1|   4|  3.0|  3.0|14.0| 8.0|300|81.0|-3.5|1022.3|-19.4| 0.0|  N| 2.1|Changping|\n",
      "|  6|2013|    3|  1|   5|  3.0|  3.0|10.0|17.0|400|71.0|-4.5|1022.6|-19.5| 0.0|NNW| 1.7|Changping|\n",
      "|  7|2013|    3|  1|   6|  4.0|  6.0|12.0|22.0|500|65.0|-4.5|1023.4|-19.5| 0.0|NNW| 1.8|Changping|\n",
      "|  8|2013|    3|  1|   7|  3.0|  6.0|25.0|39.0|600|48.0|-2.1|1024.6|-20.0| 0.0| NW| 2.5|Changping|\n",
      "|  9|2013|    3|  1|   8|  9.0| 25.0|13.0|42.0|700|46.0|-0.2|1025.2|-20.5| 0.0|NNW| 2.8|Changping|\n",
      "| 10|2013|    3|  1|   9| 11.0| 29.0| 5.0|18.0|500|73.0| 0.6|1025.3|-20.4| 0.0|NNW| 3.8|Changping|\n",
      "| 11|2013|    3|  1|  10|  9.0| 10.0| 3.0|10.0|300|83.0| 2.0|1025.1|-21.3| 0.0|  N| 2.2|Changping|\n",
      "| 12|2013|    3|  1|  11|  3.0|  3.0| 4.0| 9.0|300|81.0| 3.6|1024.8|-20.7| 0.0|NNE| 2.7|Changping|\n",
      "| 13|2013|    3|  1|  12|  3.0|  6.0| 4.0| 8.0|300|90.0| 4.8|1023.8|-19.7| 0.0|  N| 3.0|Changping|\n",
      "| 14|2013|    3|  1|  13|  3.0|101.0| 5.0| 9.0|300|89.0| 5.8|1022.8|-20.6| 0.0| NE| 4.4|Changping|\n",
      "| 15|2013|    3|  1|  14|  9.0| 60.0| 5.0| 6.0|300|94.0| 5.9|1022.6|-20.5| 0.0|  N| 3.6|Changping|\n",
      "| 16|2013|    3|  1|  15|  3.0| 34.0| 6.0| 7.0|300|94.0| 6.0|1022.6|-20.4| 0.0|  N| 3.2|Changping|\n",
      "| 17|2013|    3|  1|  16|  3.0| 28.0| 5.0| 9.0|300|92.0| 5.4|1022.8|-20.0| 0.0| NE| 2.2|Changping|\n",
      "| 18|2013|    3|  1|  17|  6.0| 25.0|19.0|12.0|300|88.0| 3.5|1023.4|-20.8| 0.0|ENE| 2.0|Changping|\n",
      "| 19|2013|    3|  1|  18|  4.0| 17.0|40.0|22.0|600|77.0| 2.7|1024.2|-20.0| 0.0| NE| 3.6|Changping|\n",
      "| 20|2013|    3|  1|  19|  7.0| 19.0|37.0|22.0|600|75.0| 2.0|1025.1|-19.3| 0.0|ENE| 1.7|Changping|\n",
      "+---+----+-----+---+----+-----+-----+----+----+---+----+----+------+-----+----+---+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the visualise of the dataset\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No',\n",
       " 'year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'hour',\n",
       " 'PM2.5',\n",
       " 'PM10',\n",
       " 'SO2',\n",
       " 'NO2',\n",
       " 'CO',\n",
       " 'O3',\n",
       " 'TEMP',\n",
       " 'PRES',\n",
       " 'DEWP',\n",
       " 'RAIN',\n",
       " 'wd',\n",
       " 'WSPM',\n",
       " 'station']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the columns name of the dataset\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- No: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- PM2.5: double (nullable = true)\n",
      " |-- PM10: double (nullable = true)\n",
      " |-- SO2: double (nullable = true)\n",
      " |-- NO2: double (nullable = true)\n",
      " |-- CO: integer (nullable = true)\n",
      " |-- O3: double (nullable = true)\n",
      " |-- TEMP: double (nullable = true)\n",
      " |-- PRES: double (nullable = true)\n",
      " |-- DEWP: double (nullable = true)\n",
      " |-- RAIN: double (nullable = true)\n",
      " |-- wd: string (nullable = true)\n",
      " |-- WSPM: double (nullable = true)\n",
      " |-- station: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the data type in the dataset\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35064"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the size of the dataset\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No',\n",
       " 'year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'hour',\n",
       " 'Target',\n",
       " 'PM10',\n",
       " 'SO2',\n",
       " 'NO2',\n",
       " 'CO',\n",
       " 'O3',\n",
       " 'TEMP',\n",
       " 'PRES',\n",
       " 'DEWP',\n",
       " 'RAIN',\n",
       " 'wd',\n",
       " 'WSPM',\n",
       " 'station']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the dataset's target column, from PM2.5 to Target\n",
    "df1 = df.withColumnRenamed(\"PM2.5\",\"Target\")\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+-----------------+\n",
      "|summary|              year|            month|               day|             hour|\n",
      "+-------+------------------+-----------------+------------------+-----------------+\n",
      "|  count|             35064|            35064|             35064|            35064|\n",
      "|   mean| 2014.662559890486|6.522929500342231|15.729637234770705|             11.5|\n",
      "| stddev|1.1772134318242622|3.448752360047857|  8.80021752943156|6.922285262428006|\n",
      "|    min|              2013|                1|                 1|                0|\n",
      "|    max|              2017|               12|                31|               23|\n",
      "+-------+------------------+-----------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generated the descriptive statistics of the dataset\n",
    "# To perform better layout, separate the columns into three parts\n",
    "# Time attributes \n",
    "df1.describe([\n",
    "    'year',\n",
    "    'month',\n",
    "    'day',\n",
    "    'hour',\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------------+------------------+------------------+------------------+------------------+\n",
      "|summary|           Target|             PM10|               SO2|               NO2|                CO|                O3|\n",
      "+-------+-----------------+-----------------+------------------+------------------+------------------+------------------+\n",
      "|  count|            34290|            34482|             34436|             34397|             33543|             34460|\n",
      "|   mean|71.09974336541265|94.65787077315701|14.958905587176204| 44.18208550745705|1152.3013445428255|57.940002617527554|\n",
      "| stddev| 72.3269261250205|83.44173842092754|20.975331415701525|29.519796285531235|1103.0562821491628| 54.31667439264105|\n",
      "|    min|              2.0|              2.0|            0.2856|            1.8477|               100|            0.2142|\n",
      "|    max|            882.0|            999.0|             310.0|             226.0|             10000|             429.0|\n",
      "+-------+-----------------+-----------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The concentration of Inorganic air pollutants, and PM\n",
    "df1.describe([\n",
    "    'Target',\n",
    "    'PM10',\n",
    "    'SO2',\n",
    "    'NO2',\n",
    "    'CO',\n",
    "    'O3',\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+-------------------+-----+------------------+---------+\n",
      "|summary|              TEMP|              PRES|              DEWP|               RAIN|   wd|              WSPM|  station|\n",
      "+-------+------------------+------------------+------------------+-------------------+-----+------------------+---------+\n",
      "|  count|             35011|             35014|             35011|              35013|34924|             35021|    35064|\n",
      "|   mean| 13.68611128792636|1007.7602777935998|1.5054954157264813|0.06036614971581961| null|1.8538362696667647|     null|\n",
      "| stddev|11.365312950567468|10.225663530494572|13.822098888069776| 0.7528993068240762| null|1.3098083299251684|     null|\n",
      "|    min|             -16.6|             982.4|             -35.1|                0.0|    E|               0.0|Changping|\n",
      "|    max|              41.4|            1036.5|              27.2|               52.1|  WSW|              10.0|Changping|\n",
      "+-------+------------------+------------------+------------------+-------------------+-----+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The Influencing factors in the dataset\n",
    "df1.describe([\n",
    "    'TEMP',\n",
    "    'PRES',\n",
    "    'DEWP',\n",
    "    'RAIN',\n",
    "    'wd',\n",
    "    'WSPM',\n",
    "    'station'\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32681"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the null value\n",
    "df2 = df1.na.drop()\n",
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import VectorAssembler and Vectors to vectorization the data\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input columns are the feature column names, and the output column is the feature.\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"month\", \"hour\", \"PM10\", \"SO2\", 'NO2',\n",
    "               \"CO\", \"O3\", \"TEMP\", \"DEWP\", \"RAIN\", \"WSPM\"],\n",
    "    outputCol=\"Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we've created the assembler variable, let's actually transform the data.\n",
    "df3 = assembler.transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- No: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- Target: double (nullable = true)\n",
      " |-- PM10: double (nullable = true)\n",
      " |-- SO2: double (nullable = true)\n",
      " |-- NO2: double (nullable = true)\n",
      " |-- CO: integer (nullable = true)\n",
      " |-- O3: double (nullable = true)\n",
      " |-- TEMP: double (nullable = true)\n",
      " |-- PRES: double (nullable = true)\n",
      " |-- DEWP: double (nullable = true)\n",
      " |-- RAIN: double (nullable = true)\n",
      " |-- wd: string (nullable = true)\n",
      " |-- WSPM: double (nullable = true)\n",
      " |-- station: string (nullable = true)\n",
      " |-- Features: vector (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(No=1, year=2013, month=3, day=1, hour=0, Target=3.0, PM10=6.0, SO2=13.0, NO2=7.0, CO=300, O3=85.0, TEMP=-2.3, PRES=1020.8, DEWP=-19.7, RAIN=0.0, wd='E', WSPM=0.5, station='Changping', Features=DenseVector([3.0, 0.0, 6.0, 13.0, 7.0, 300.0, 85.0, -2.3, -19.7, 0.0, 0.5]))]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using print schema, the features output column has been added. \n",
    "df3.printSchema()\n",
    "# The \"features\" column is a dense vector that combines the various features as expected.\n",
    "df3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            Features|Target|\n",
      "+--------------------+------+\n",
      "|[3.0,0.0,6.0,13.0...|   3.0|\n",
      "|[3.0,1.0,3.0,6.0,...|   3.0|\n",
      "|[3.0,2.0,3.0,22.0...|   3.0|\n",
      "|[3.0,3.0,6.0,12.0...|   3.0|\n",
      "|[3.0,4.0,3.0,14.0...|   3.0|\n",
      "|[3.0,5.0,3.0,10.0...|   3.0|\n",
      "|[3.0,6.0,6.0,12.0...|   4.0|\n",
      "|[3.0,7.0,6.0,25.0...|   3.0|\n",
      "|[3.0,8.0,25.0,13....|   9.0|\n",
      "|[3.0,9.0,29.0,5.0...|  11.0|\n",
      "|[3.0,10.0,10.0,3....|   9.0|\n",
      "|[3.0,11.0,3.0,4.0...|   3.0|\n",
      "|[3.0,12.0,6.0,4.0...|   3.0|\n",
      "|[3.0,13.0,101.0,5...|   3.0|\n",
      "|[3.0,14.0,60.0,5....|   9.0|\n",
      "|[3.0,15.0,34.0,6....|   3.0|\n",
      "|[3.0,16.0,28.0,5....|   3.0|\n",
      "|[3.0,17.0,25.0,19...|   6.0|\n",
      "|[3.0,18.0,17.0,40...|   4.0|\n",
      "|[3.0,19.0,19.0,37...|   7.0|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's select two columns (the feature and predictor).\n",
    "# This is now in the appropriate format to be processed by Spark.\n",
    "dataset = df3.select(\"Features\",\"Target\")\n",
    "dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid overfit, do a randomised 70/30 split. \n",
    "train_data,test_data = dataset.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|           Target|\n",
      "+-------+-----------------+\n",
      "|  count|            22934|\n",
      "|   mean|69.96537455306532|\n",
      "| stddev|70.81669153788606|\n",
      "|    min|              3.0|\n",
      "|    max|            581.0|\n",
      "+-------+-----------------+\n",
      "\n",
      "+-------+-----------------+\n",
      "|summary|           Target|\n",
      "+-------+-----------------+\n",
      "|  count|             9747|\n",
      "|   mean|71.12868574946138|\n",
      "| stddev|71.27837864606425|\n",
      "|    min|              3.0|\n",
      "|    max|            662.0|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The descriptive statistics of training data.\n",
    "train_data.describe().show()\n",
    "\n",
    "# The descriptive statistics of testing data.\n",
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
