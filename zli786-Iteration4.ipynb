{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section must be included at the beginning of each new notebook. Remember to change the app name. \n",
    "# If you're using VirtualBox, change the below to '/home/user/spark-2.1.1-bin-hadoop2.7'\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('zli786-Iteration4').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the dataset\n",
    "df_1 = spark.read.options(header='True', inferSchema='True').csv(\"./dataset1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- No: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- PM2.5: double (nullable = true)\n",
      " |-- PM10: double (nullable = true)\n",
      " |-- SO2: double (nullable = true)\n",
      " |-- NO2: double (nullable = true)\n",
      " |-- CO: integer (nullable = true)\n",
      " |-- O3: double (nullable = true)\n",
      " |-- TEMP: double (nullable = true)\n",
      " |-- PRES: double (nullable = true)\n",
      " |-- DEWP: double (nullable = true)\n",
      " |-- RAIN: double (nullable = true)\n",
      " |-- wd: string (nullable = true)\n",
      " |-- WSPM: double (nullable = true)\n",
      " |-- station: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Input the second dataset\n",
    "df_2 = spark.read.options(header='True', inferSchema='True').csv(\"./dataset2.csv\")\n",
    "df_2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5065"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29999"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35064"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_2.union(df_1)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+---+----+-----+-----+----+----+---+----+----+------+-----+----+---+----+---------+\n",
      "| No|year|month|day|hour|PM2.5| PM10| SO2| NO2| CO|  O3|TEMP|  PRES| DEWP|RAIN| wd|WSPM|  station|\n",
      "+---+----+-----+---+----+-----+-----+----+----+---+----+----+------+-----+----+---+----+---------+\n",
      "|  1|2013|    3|  1|   0|  3.0|  6.0|13.0| 7.0|300|85.0|-2.3|1020.8|-19.7| 0.0|  E| 0.5|Changping|\n",
      "|  2|2013|    3|  1|   1|  3.0|  3.0| 6.0| 6.0|300|85.0|-2.5|1021.3|-19.0| 0.0|ENE| 0.7|Changping|\n",
      "|  3|2013|    3|  1|   2|  3.0|  3.0|22.0|13.0|400|74.0|-3.0|1021.3|-19.9| 0.0|ENE| 0.2|Changping|\n",
      "|  4|2013|    3|  1|   3|  3.0|  6.0|12.0| 8.0|300|81.0|-3.6|1021.8|-19.1| 0.0|NNE| 1.0|Changping|\n",
      "|  5|2013|    3|  1|   4|  3.0|  3.0|14.0| 8.0|300|81.0|-3.5|1022.3|-19.4| 0.0|  N| 2.1|Changping|\n",
      "|  6|2013|    3|  1|   5|  3.0|  3.0|10.0|17.0|400|71.0|-4.5|1022.6|-19.5| 0.0|NNW| 1.7|Changping|\n",
      "|  7|2013|    3|  1|   6|  4.0|  6.0|12.0|22.0|500|65.0|-4.5|1023.4|-19.5| 0.0|NNW| 1.8|Changping|\n",
      "|  8|2013|    3|  1|   7|  3.0|  6.0|25.0|39.0|600|48.0|-2.1|1024.6|-20.0| 0.0| NW| 2.5|Changping|\n",
      "|  9|2013|    3|  1|   8|  9.0| 25.0|13.0|42.0|700|46.0|-0.2|1025.2|-20.5| 0.0|NNW| 2.8|Changping|\n",
      "| 10|2013|    3|  1|   9| 11.0| 29.0| 5.0|18.0|500|73.0| 0.6|1025.3|-20.4| 0.0|NNW| 3.8|Changping|\n",
      "| 11|2013|    3|  1|  10|  9.0| 10.0| 3.0|10.0|300|83.0| 2.0|1025.1|-21.3| 0.0|  N| 2.2|Changping|\n",
      "| 12|2013|    3|  1|  11|  3.0|  3.0| 4.0| 9.0|300|81.0| 3.6|1024.8|-20.7| 0.0|NNE| 2.7|Changping|\n",
      "| 13|2013|    3|  1|  12|  3.0|  6.0| 4.0| 8.0|300|90.0| 4.8|1023.8|-19.7| 0.0|  N| 3.0|Changping|\n",
      "| 14|2013|    3|  1|  13|  3.0|101.0| 5.0| 9.0|300|89.0| 5.8|1022.8|-20.6| 0.0| NE| 4.4|Changping|\n",
      "| 15|2013|    3|  1|  14|  9.0| 60.0| 5.0| 6.0|300|94.0| 5.9|1022.6|-20.5| 0.0|  N| 3.6|Changping|\n",
      "| 16|2013|    3|  1|  15|  3.0| 34.0| 6.0| 7.0|300|94.0| 6.0|1022.6|-20.4| 0.0|  N| 3.2|Changping|\n",
      "| 17|2013|    3|  1|  16|  3.0| 28.0| 5.0| 9.0|300|92.0| 5.4|1022.8|-20.0| 0.0| NE| 2.2|Changping|\n",
      "| 18|2013|    3|  1|  17|  6.0| 25.0|19.0|12.0|300|88.0| 3.5|1023.4|-20.8| 0.0|ENE| 2.0|Changping|\n",
      "| 19|2013|    3|  1|  18|  4.0| 17.0|40.0|22.0|600|77.0| 2.7|1024.2|-20.0| 0.0| NE| 3.6|Changping|\n",
      "| 20|2013|    3|  1|  19|  7.0| 19.0|37.0|22.0|600|75.0| 2.0|1025.1|-19.3| 0.0|ENE| 1.7|Changping|\n",
      "+---+----+-----+---+----+-----+-----+----+----+---+----+----+------+-----+----+---+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the visualise of the dataset\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No',\n",
       " 'year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'hour',\n",
       " 'PM2.5',\n",
       " 'PM10',\n",
       " 'SO2',\n",
       " 'NO2',\n",
       " 'CO',\n",
       " 'O3',\n",
       " 'TEMP',\n",
       " 'PRES',\n",
       " 'DEWP',\n",
       " 'RAIN',\n",
       " 'wd',\n",
       " 'WSPM',\n",
       " 'station']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the columns name of the dataset\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- No: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- PM2.5: double (nullable = true)\n",
      " |-- PM10: double (nullable = true)\n",
      " |-- SO2: double (nullable = true)\n",
      " |-- NO2: double (nullable = true)\n",
      " |-- CO: integer (nullable = true)\n",
      " |-- O3: double (nullable = true)\n",
      " |-- TEMP: double (nullable = true)\n",
      " |-- PRES: double (nullable = true)\n",
      " |-- DEWP: double (nullable = true)\n",
      " |-- RAIN: double (nullable = true)\n",
      " |-- wd: string (nullable = true)\n",
      " |-- WSPM: double (nullable = true)\n",
      " |-- station: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the data type in the dataset\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35064"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the size of the dataset\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No',\n",
       " 'year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'hour',\n",
       " 'Target',\n",
       " 'PM10',\n",
       " 'SO2',\n",
       " 'NO2',\n",
       " 'CO',\n",
       " 'O3',\n",
       " 'TEMP',\n",
       " 'PRES',\n",
       " 'DEWP',\n",
       " 'RAIN',\n",
       " 'wd',\n",
       " 'WSPM',\n",
       " 'station']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the dataset's target column, from PM2.5 to Target\n",
    "df1 = df.withColumnRenamed(\"PM2.5\",\"Target\")\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+-----------------+\n",
      "|summary|              year|            month|               day|             hour|\n",
      "+-------+------------------+-----------------+------------------+-----------------+\n",
      "|  count|             35064|            35064|             35064|            35064|\n",
      "|   mean| 2014.662559890486|6.522929500342231|15.729637234770705|             11.5|\n",
      "| stddev|1.1772134318241192| 3.44875236004786| 8.800217529431587|6.922285262427998|\n",
      "|    min|              2013|                1|                 1|                0|\n",
      "|    max|              2017|               12|                31|               23|\n",
      "+-------+------------------+-----------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generated the descriptive statistics of the dataset\n",
    "# To perform better layout, separate the columns into three parts\n",
    "# Time attributes \n",
    "df1.describe([\n",
    "    'year',\n",
    "    'month',\n",
    "    'day',\n",
    "    'hour',\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------------+------------------+------------------+------------------+------------------+\n",
      "|summary|           Target|             PM10|               SO2|               NO2|                CO|                O3|\n",
      "+-------+-----------------+-----------------+------------------+------------------+------------------+------------------+\n",
      "|  count|            34290|            34482|             34436|             34397|             33543|             34460|\n",
      "|   mean|71.09974336541265|94.65787077315701|14.958905587176204| 44.18208550745705|1152.3013445428255|57.940002617527554|\n",
      "| stddev| 72.3269261250207|83.44173842092758| 20.97533141570151|29.519796285531175| 1103.056282149164|54.316674392640884|\n",
      "|    min|              2.0|              2.0|            0.2856|            1.8477|               100|            0.2142|\n",
      "|    max|            882.0|            999.0|             310.0|             226.0|             10000|             429.0|\n",
      "+-------+-----------------+-----------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The concentration of Inorganic air pollutants, and PM\n",
    "df1.describe([\n",
    "    'Target',\n",
    "    'PM10',\n",
    "    'SO2',\n",
    "    'NO2',\n",
    "    'CO',\n",
    "    'O3',\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+-----+------------------+---------+\n",
      "|summary|              TEMP|              PRES|              DEWP|              RAIN|   wd|              WSPM|  station|\n",
      "+-------+------------------+------------------+------------------+------------------+-----+------------------+---------+\n",
      "|  count|             35011|             35014|             35011|             35013|34924|             35021|    35064|\n",
      "|   mean|13.686111287926389|1007.7602777935974|1.5054954157264748|0.0603661497158197| null|1.8538362696667694|     null|\n",
      "| stddev|11.365312950567448| 10.22566353049497|13.822098888069743|0.7528993068240725| null|1.3098083299251684|     null|\n",
      "|    min|             -16.6|             982.4|             -35.1|               0.0|    E|               0.0|Changping|\n",
      "|    max|              41.4|            1036.5|              27.2|              52.1|  WSW|              10.0|Changping|\n",
      "+-------+------------------+------------------+------------------+------------------+-----+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The Influencing factors in the dataset\n",
    "df1.describe([\n",
    "    'TEMP',\n",
    "    'PRES',\n",
    "    'DEWP',\n",
    "    'RAIN',\n",
    "    'wd',\n",
    "    'WSPM',\n",
    "    'station'\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32681"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the null value\n",
    "df2 = df1.na.drop()\n",
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- No: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- Target: double (nullable = true)\n",
      " |-- PM10: double (nullable = true)\n",
      " |-- SO2: double (nullable = true)\n",
      " |-- NO2: double (nullable = true)\n",
      " |-- CO: integer (nullable = true)\n",
      " |-- O3: double (nullable = true)\n",
      " |-- TEMP: double (nullable = true)\n",
      " |-- PRES: double (nullable = true)\n",
      " |-- DEWP: double (nullable = true)\n",
      " |-- RAIN: double (nullable = true)\n",
      " |-- wd: string (nullable = true)\n",
      " |-- WSPM: double (nullable = true)\n",
      " |-- station: string (nullable = true)\n",
      "\n",
      "+-------+-----------------+-----------------+------------------+-----------------+------------------+-----------------+\n",
      "|summary|           Target|             PM10|               SO2|              NO2|                CO|               O3|\n",
      "+-------+-----------------+-----------------+------------------+-----------------+------------------+-----------------+\n",
      "|  count|            32681|            32681|             32681|            32681|             32681|            32681|\n",
      "|   mean|  70.312328264129|94.08640188488725|15.061356751629388|44.31903533857593|1151.7164407453872|57.42454079128545|\n",
      "| stddev|70.95560721978563|82.61033990235144| 21.05757421177148| 29.5913748794491|   1105.6466366089| 53.7926034257126|\n",
      "|    min|              3.0|              2.0|               1.0|              2.0|               100|           0.2142|\n",
      "|    max|            662.0|            992.0|             310.0|            208.0|             10000|            429.0|\n",
      "+-------+-----------------+-----------------+------------------+-----------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()\n",
    "df2.describe([\n",
    "    'Target',\n",
    "    'PM10',\n",
    "    'SO2',\n",
    "    'NO2',\n",
    "    'CO',\n",
    "    'O3',\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['month',\n",
       " 'hour',\n",
       " 'Target',\n",
       " 'SO2',\n",
       " 'NO2',\n",
       " 'CO',\n",
       " 'O3',\n",
       " 'TEMP',\n",
       " 'DEWP',\n",
       " 'RAIN',\n",
       " 'WSPM']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_filter = df2.drop('No','year', 'day', 'PM10',\n",
    "                      'PRES','wd','station')\n",
    "df2_filter.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import VectorAssembler and Vectors to vectorization the data\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input columns are the feature column names, and the output column is the feature.\n",
    "assembler = VectorAssembler(\n",
    "inputCols=[\"month\", \"hour\", \"SO2\", 'NO2', \"CO\", \n",
    "           \"O3\", \"TEMP\", \"DEWP\", \"RAIN\", \"WSPM\"],\n",
    "outputCol=\"Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we've created the assembler variable, let's actually transform the data.\n",
    "df3 = assembler.transform(df2_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- month: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- Target: double (nullable = true)\n",
      " |-- SO2: double (nullable = true)\n",
      " |-- NO2: double (nullable = true)\n",
      " |-- CO: integer (nullable = true)\n",
      " |-- O3: double (nullable = true)\n",
      " |-- TEMP: double (nullable = true)\n",
      " |-- DEWP: double (nullable = true)\n",
      " |-- RAIN: double (nullable = true)\n",
      " |-- WSPM: double (nullable = true)\n",
      " |-- Features: vector (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(month=3, hour=0, Target=3.0, SO2=13.0, NO2=7.0, CO=300, O3=85.0, TEMP=-2.3, DEWP=-19.7, RAIN=0.0, WSPM=0.5, Features=DenseVector([3.0, 0.0, 13.0, 7.0, 300.0, 85.0, -2.3, -19.7, 0.0, 0.5]))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using print schema, the features output column has been added. \n",
    "df3.printSchema()\n",
    "# The \"features\" column is a dense vector that combines the various features as expected.\n",
    "df3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            Features|Target|\n",
      "+--------------------+------+\n",
      "|[3.0,0.0,13.0,7.0...|   3.0|\n",
      "|[3.0,1.0,6.0,6.0,...|   3.0|\n",
      "|[3.0,2.0,22.0,13....|   3.0|\n",
      "|[3.0,3.0,12.0,8.0...|   3.0|\n",
      "|[3.0,4.0,14.0,8.0...|   3.0|\n",
      "|[3.0,5.0,10.0,17....|   3.0|\n",
      "|[3.0,6.0,12.0,22....|   4.0|\n",
      "|[3.0,7.0,25.0,39....|   3.0|\n",
      "|[3.0,8.0,13.0,42....|   9.0|\n",
      "|[3.0,9.0,5.0,18.0...|  11.0|\n",
      "|[3.0,10.0,3.0,10....|   9.0|\n",
      "|[3.0,11.0,4.0,9.0...|   3.0|\n",
      "|[3.0,12.0,4.0,8.0...|   3.0|\n",
      "|[3.0,13.0,5.0,9.0...|   3.0|\n",
      "|[3.0,14.0,5.0,6.0...|   9.0|\n",
      "|[3.0,15.0,6.0,7.0...|   3.0|\n",
      "|[3.0,16.0,5.0,9.0...|   3.0|\n",
      "|[3.0,17.0,19.0,12...|   6.0|\n",
      "|[3.0,18.0,40.0,22...|   4.0|\n",
      "|[3.0,19.0,37.0,22...|   7.0|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's select two columns (the feature and predictor).\n",
    "# This is now in the appropriate format to be processed by Spark.\n",
    "dataset = df3.select(\"Features\",\"Target\")\n",
    "dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid overfit, do a randomised 70/30 split. \n",
    "train_data,test_data = dataset.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|           Target|\n",
      "+-------+-----------------+\n",
      "|  count|            23048|\n",
      "|   mean| 70.2375216938563|\n",
      "| stddev|71.17829361527279|\n",
      "|    min|              3.0|\n",
      "|    max|            581.0|\n",
      "+-------+-----------------+\n",
      "\n",
      "+-------+-----------------+\n",
      "|summary|           Target|\n",
      "+-------+-----------------+\n",
      "|  count|             9633|\n",
      "|   mean|70.49131111803177|\n",
      "| stddev|70.42330404614813|\n",
      "|    min|              3.0|\n",
      "|    max|            662.0|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The descriptive statistics of training data.\n",
    "train_data.describe().show()\n",
    "\n",
    "# The descriptive statistics of testing data.\n",
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Linear Regression model\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Linear Regression model\n",
    "lr = LinearRegression(labelCol='Target',featuresCol='Features')\n",
    "# Fit the model\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -10.738517782818937\n",
      "Coefficients: [-1.1568311191555523,-0.20028479384310988,0.3836006506746051,0.930698185377942,0.030858662060314027,0.3067638818096114,-1.3056688024742853,1.93683197727284,-1.6729262264879232,3.2619202144037582]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Coefficients:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DenseVector([-1.1568, -0.2003, 0.3836, 0.9307, 0.0309, 0.3068, -1.3057, 1.9368, -1.6729, 3.2619])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the coefficients and intercept for Linear Regression.\n",
    "print(\"Intercept:\",lr_model.intercept)\n",
    "print(\"Coefficients:\",lr_model.coefficients)\n",
    "display(\"Coefficients:\",lr_model.coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression\n",
      "R2: 0.7038064757649373\n",
      "MAE: 26.084266332326752\n",
      "MSE: 1468.8020390872548\n",
      "RSME: 38.324953217026305\n",
      "Explained variance: 3568.0285331556306\n",
      "+--------------------+------+-------------------+\n",
      "|            Features|Target|         prediction|\n",
      "+--------------------+------+-------------------+\n",
      "|[1.0,0.0,3.0,14.0...|  14.0|  4.688619087199685|\n",
      "|[1.0,0.0,5.0,11.0...|   8.0|  8.505467159391147|\n",
      "|[1.0,0.0,6.0,22.0...|  12.0|   8.68382282692786|\n",
      "|[1.0,0.0,6.0,26.0...|  15.0|  19.40342179277104|\n",
      "|[1.0,0.0,7.0,36.0...|  24.0| 53.699074648820165|\n",
      "|[1.0,0.0,8.0,112....| 255.0|  276.1904477085751|\n",
      "|[1.0,0.0,9.0,31.0...|  15.0| 27.222367119211675|\n",
      "|[1.0,0.0,10.0,14....|  20.0|  0.489921981407905|\n",
      "|[1.0,0.0,10.0,65....|  87.0| 110.60889154383187|\n",
      "|[1.0,0.0,11.0,36....|  27.0|  39.24364133938381|\n",
      "|[1.0,0.0,12.0,101...| 115.0| 158.14344735640574|\n",
      "|[1.0,0.0,14.0,17....|  16.0|-7.0152186308313835|\n",
      "|[1.0,0.0,14.0,58....|  59.0|  75.18610841030814|\n",
      "|[1.0,0.0,16.0,32....|  14.0| 19.129685006756986|\n",
      "|[1.0,0.0,18.0,23....|  20.0| 13.208386578912988|\n",
      "|[1.0,0.0,21.0,36....|  29.0| 43.608355697685724|\n",
      "|[1.0,0.0,26.0,81....|  62.0| 105.28977897277692|\n",
      "|[1.0,0.0,33.0,79....| 103.0|  128.7188839317576|\n",
      "|[1.0,0.0,41.0,19....|  13.0|  20.60832511060778|\n",
      "|[1.0,0.0,42.0,77....|  93.0| 116.35735500201179|\n",
      "+--------------------+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To evaluate the model against the test data.\n",
    "test_results = lr_model.evaluate(test_data)\n",
    "print ('Model: Linear Regression')\n",
    "# Evaluation metrics \n",
    "# R2\n",
    "print(\"R2: {}\".format(test_results.r2))\n",
    "# Mean Absolute Error\n",
    "print(\"MAE: {}\".format(test_results.meanAbsoluteError))\n",
    "# Mean Squared Error\n",
    "print(\"MSE: {}\".format(test_results.meanSquaredError))\n",
    "# root of Mean Squared Error\n",
    "print(\"RSME: {}\".format(test_results.rootMeanSquaredError))\n",
    "# Explained Variance\n",
    "print(\"Explained variance: {}\".format(test_results.explainedVariance))\n",
    "# This shows the difference between the predicted value and the test data.\n",
    "test_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Random Forest Regressor model\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+\n",
      "|            Features|Target|     indexedFeatures|\n",
      "+--------------------+------+--------------------+\n",
      "|[3.0,0.0,13.0,7.0...|   3.0|[3.0,0.0,13.0,7.0...|\n",
      "|[3.0,1.0,6.0,6.0,...|   3.0|[3.0,1.0,6.0,6.0,...|\n",
      "|[3.0,2.0,22.0,13....|   3.0|[3.0,2.0,22.0,13....|\n",
      "|[3.0,3.0,12.0,8.0...|   3.0|[3.0,3.0,12.0,8.0...|\n",
      "|[3.0,4.0,14.0,8.0...|   3.0|[3.0,4.0,14.0,8.0...|\n",
      "|[3.0,5.0,10.0,17....|   3.0|[3.0,5.0,10.0,17....|\n",
      "|[3.0,6.0,12.0,22....|   4.0|[3.0,6.0,12.0,22....|\n",
      "|[3.0,7.0,25.0,39....|   3.0|[3.0,7.0,25.0,39....|\n",
      "|[3.0,8.0,13.0,42....|   9.0|[3.0,8.0,13.0,42....|\n",
      "|[3.0,9.0,5.0,18.0...|  11.0|[3.0,9.0,5.0,18.0...|\n",
      "|[3.0,10.0,3.0,10....|   9.0|[3.0,10.0,3.0,10....|\n",
      "|[3.0,11.0,4.0,9.0...|   3.0|[3.0,11.0,4.0,9.0...|\n",
      "|[3.0,12.0,4.0,8.0...|   3.0|[3.0,12.0,4.0,8.0...|\n",
      "|[3.0,13.0,5.0,9.0...|   3.0|[3.0,13.0,5.0,9.0...|\n",
      "|[3.0,14.0,5.0,6.0...|   9.0|[3.0,14.0,5.0,6.0...|\n",
      "|[3.0,15.0,6.0,7.0...|   3.0|[3.0,15.0,6.0,7.0...|\n",
      "|[3.0,16.0,5.0,9.0...|   3.0|[3.0,16.0,5.0,9.0...|\n",
      "|[3.0,17.0,19.0,12...|   6.0|[3.0,17.0,19.0,12...|\n",
      "|[3.0,18.0,40.0,22...|   4.0|[3.0,18.0,40.0,22...|\n",
      "|[3.0,19.0,37.0,22...|   7.0|[3.0,19.0,37.0,22...|\n",
      "+--------------------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featureIndexer = VectorIndexer(inputCol=\"Features\",\n",
    "                               outputCol=\"indexedFeatures\",maxCategories=4).fit(dataset)\n",
    "dataset1=featureIndexer.transform(dataset)\n",
    "dataset1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|           Target|\n",
      "+-------+-----------------+\n",
      "|  count|            22816|\n",
      "|   mean| 69.9772966339411|\n",
      "| stddev|70.83501777465986|\n",
      "|    min|              3.0|\n",
      "|    max|            662.0|\n",
      "+-------+-----------------+\n",
      "\n",
      "+-------+-----------------+\n",
      "|summary|           Target|\n",
      "+-------+-----------------+\n",
      "|  count|             9865|\n",
      "|   mean|71.08719716168271|\n",
      "| stddev|71.23128852707381|\n",
      "|    min|              3.0|\n",
      "|    max|            581.0|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(trainingData,testData)=dataset1.randomSplit([0.7,0.3])\n",
    "trainingData.describe().show()\n",
    "testData.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+\n",
      "|        prediction|            Features|\n",
      "+------------------+--------------------+\n",
      "|15.492531522527804|[1.0,0.0,2.0,17.0...|\n",
      "| 16.07256616288987|[1.0,0.0,3.0,14.0...|\n",
      "|15.492531522527804|[1.0,0.0,4.0,15.0...|\n",
      "|17.108843474027875|[1.0,0.0,4.0,31.0...|\n",
      "|18.823733195680532|[1.0,0.0,5.0,28.0...|\n",
      "|119.17584857232058|[1.0,0.0,6.0,72.0...|\n",
      "| 62.05518282637926|[1.0,0.0,7.0,36.0...|\n",
      "|141.91294733802906|[1.0,0.0,9.0,88.0...|\n",
      "|16.875159011285266|[1.0,0.0,10.0,14....|\n",
      "| 23.58997579726961|[1.0,0.0,11.0,36....|\n",
      "|16.980861630075903|[1.0,0.0,14.0,17....|\n",
      "| 25.00017950155124|[1.0,0.0,17.0,28....|\n",
      "|16.926347661468302|[1.0,0.0,18.0,11....|\n",
      "|  86.0863976648339|[1.0,0.0,19.0,65....|\n",
      "|215.93030016040734|[1.0,0.0,21.0,107...|\n",
      "| 93.01413925007589|[1.0,0.0,26.0,81....|\n",
      "| 95.87508891909306|[1.0,0.0,27.0,77....|\n",
      "|142.63396947264255|[1.0,0.0,34.0,100...|\n",
      "|20.591870515432092|[1.0,0.0,41.0,19....|\n",
      "| 47.30009240649021|[1.0,0.0,41.0,32....|\n",
      "+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Random Forest model\n",
    "rf = RandomForestRegressor(featuresCol=\"indexedFeatures\",labelCol=\"Target\")\n",
    "# Fit the model\n",
    "rf_model = rf.fit(trainingData)\n",
    "rf_predictions = rf_model.transform(testData)\n",
    "rf_predictions.select('prediction','Features').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model's RMSE is 36.938606\n",
      "Random Forest Model's R2 is 0.731055\n",
      "Random Forest Model's MAE is 23.647403\n",
      "Random Forest Model's MSE is 1364.460602\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"Target\",predictionCol=\"prediction\")\n",
    "rf_rmse = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"rmse\"})\n",
    "print(\"Random Forest Model's RMSE is %f\"%rf_rmse)\n",
    "# r^2 metric\n",
    "rf_r2 = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"r2\"})\n",
    "print(\"Random Forest Model's R2 is %f\"%rf_r2)\n",
    "# mean absolute error \n",
    "rf_mae = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"mae\"})\n",
    "print(\"Random Forest Model's MAE is %f\"%rf_mae)\n",
    "# mean squared error\n",
    "rf_mse = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"mse\"})\n",
    "print(\"Random Forest Model's MSE is %f\"%rf_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(10, {0: 0.0122, 1: 0.0018, 2: 0.0516, 3: 0.2622, 4: 0.5438, 5: 0.0583, 6: 0.0165, 7: 0.0435, 9: 0.0102})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "featureImportances = rf_model.featureImportances\n",
    "display(featureImportances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressionModel (uid=rfr_e7874167af0d) with 20 trees\n"
     ]
    }
   ],
   "source": [
    "treeModel = rf_model\n",
    "# summary only\n",
    "print(treeModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Decision Tree model\n",
    "from pyspark.ml.regression import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+\n",
      "|        prediction|            Features|\n",
      "+------------------+--------------------+\n",
      "|14.105080027835768|[1.0,0.0,2.0,17.0...|\n",
      "|14.105080027835768|[1.0,0.0,3.0,14.0...|\n",
      "|14.105080027835768|[1.0,0.0,4.0,15.0...|\n",
      "|14.105080027835768|[1.0,0.0,4.0,31.0...|\n",
      "|16.242380261248186|[1.0,0.0,5.0,28.0...|\n",
      "|169.97552742616034|[1.0,0.0,6.0,72.0...|\n",
      "| 69.36691410392365|[1.0,0.0,7.0,36.0...|\n",
      "|169.97552742616034|[1.0,0.0,9.0,88.0...|\n",
      "|14.105080027835768|[1.0,0.0,10.0,14....|\n",
      "|16.242380261248186|[1.0,0.0,11.0,36....|\n",
      "|14.105080027835768|[1.0,0.0,14.0,17....|\n",
      "|33.736559139784944|[1.0,0.0,17.0,28....|\n",
      "|14.105080027835768|[1.0,0.0,18.0,11....|\n",
      "| 95.90480167014614|[1.0,0.0,19.0,65....|\n",
      "| 229.4227642276423|[1.0,0.0,21.0,107...|\n",
      "| 69.36691410392365|[1.0,0.0,26.0,81....|\n",
      "| 95.90480167014614|[1.0,0.0,27.0,77....|\n",
      "| 186.9644128113879|[1.0,0.0,34.0,100...|\n",
      "|14.105080027835768|[1.0,0.0,41.0,19....|\n",
      "|33.736559139784944|[1.0,0.0,41.0,32....|\n",
      "+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Decision Tree model\n",
    "dt = DecisionTreeRegressor(labelCol=\"Target\", featuresCol=\"indexedFeatures\")\n",
    "# Fit the model\n",
    "model_dt = dt.fit(trainingData)\n",
    "dt_predictions = model_dt.transform(testData)\n",
    "dt_predictions.select('prediction','Features').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model's RMSE is 38.501183\n",
      "Decision Tree Model's R2 is 0.707820\n",
      "Decision Tree Model's MAE is 24.633771\n",
      "Decision Tree Model's MSE is 1482.341105\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"Target\",predictionCol=\"prediction\")\n",
    "dt_rmse = evaluator.evaluate(dt_predictions, {evaluator.metricName: \"rmse\"})\n",
    "print(\"Decision Tree Model's RMSE is %f\"%dt_rmse)\n",
    "# r^2 metric\n",
    "dt_r2 = evaluator.evaluate(dt_predictions, {evaluator.metricName: \"r2\"})\n",
    "print(\"Decision Tree Model's R2 is %f\"%dt_r2)\n",
    "# mean absolute error \n",
    "dt_mae = evaluator.evaluate(dt_predictions, {evaluator.metricName: \"mae\"})\n",
    "print(\"Decision Tree Model's MAE is %f\"%dt_mae)\n",
    "# mean squared error\n",
    "dt_mse = evaluator.evaluate(dt_predictions, {evaluator.metricName: \"mse\"})\n",
    "print(\"Decision Tree Model's MSE is %f\"%dt_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(10, {0: 0.018, 2: 0.0058, 3: 0.1381, 4: 0.7709, 5: 0.0063, 6: 0.0004, 7: 0.0605})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the feature importance in decision tree model\n",
    "featureImportances = model_dt.featureImportances\n",
    "display(featureImportances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressionModel (uid=DecisionTreeRegressor_4d2ca4fae82ffce81d2a) of depth 5 with 63 nodes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summary only\n",
    "display(model_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-----------------------+-------------------+\n",
      "|Model|R2 metric|Root Mean Squared Error|Mean Absolute Error|\n",
      "+-----+---------+-----------------------+-------------------+\n",
      "|   LR| 0.721782|                37.5316|            25.8532|\n",
      "|   RF| 0.739855|                 36.263|             23.543|\n",
      "|   DT| 0.715949|                38.6912|            24.7507|\n",
      "+-----+---------+-----------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r2_result = spark.createDataFrame(\n",
    "            [(\"LR\", 0.721782, 37.5316, 25.8532),\n",
    "             (\"RF\", 0.739855, 36.2630, 23.5430),\n",
    "             (\"DT\", 0.715949, 38.6912, 24.7507)],\n",
    "            [\"Model\",\"R2 metric\",\"Root Mean Squared Error\", \"Mean Absolute Error\"])\n",
    "r2_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------------+\n",
      "|Features|RF's Feature Importance|\n",
      "+--------+-----------------------+\n",
      "|   month|                 0.0096|\n",
      "|    hour|                 0.0012|\n",
      "|     SO2|                 0.0575|\n",
      "|     NO2|                 0.2559|\n",
      "|      CO|                 0.5711|\n",
      "|      O3|                 0.0294|\n",
      "|    TEMP|                 0.0115|\n",
      "|    DEWP|                 0.0538|\n",
      "|    RAIN|                 3.0E-4|\n",
      "|    WSPM|                 0.0096|\n",
      "+--------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_featureImportance = spark.createDataFrame(\n",
    "                        [('month',0.0096),\n",
    "                         ('hour',0.0012),\n",
    "                         ('SO2',0.0575),\n",
    "                         ('NO2',0.2559),\n",
    "                         ('CO',0.5711),\n",
    "                         ('O3',0.0294),\n",
    "                         ('TEMP',0.0115),\n",
    "                         ('DEWP',0.0538),\n",
    "                         ('RAIN',0.0003),\n",
    "                         ('WSPM',0.0096)],\n",
    "                        [\"Features\",\"RF's Feature Importance\"])\n",
    "rf_featureImportance.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------------+\n",
      "|Features|DT's Feature Importance|\n",
      "+--------+-----------------------+\n",
      "|   month|                 0.0212|\n",
      "|    hour|                    0.0|\n",
      "|     SO2|                 0.0038|\n",
      "|     NO2|                 0.1414|\n",
      "|      CO|                 0.7707|\n",
      "|      O3|                 0.0192|\n",
      "|    TEMP|                 2.0E-4|\n",
      "|    DEWP|                 0.0435|\n",
      "|    RAIN|                    0.0|\n",
      "|    WSPM|                    0.0|\n",
      "+--------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_featureImportance = spark.createDataFrame(\n",
    "                        [('month',0.0212),\n",
    "                         ('hour',0.0000),\n",
    "                         ('SO2',0.0038),\n",
    "                         ('NO2',0.1414),\n",
    "                         ('CO',0.7707),\n",
    "                         ('O3',0.0192),\n",
    "                         ('TEMP',0.0002),\n",
    "                         ('DEWP',0.0435),\n",
    "                         ('RAIN',0.0000),\n",
    "                         ('WSPM',0.0000)],\n",
    "                        [\"Features\",\"DT's Feature Importance\"])\n",
    "dt_featureImportance.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(trainingData1,testData1)=dataset1.randomSplit([0.8,0.2])\n",
    "trainingData1.describe().show()\n",
    "testData1.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model's RMSE is 36.314099\n",
      "Random Forest Model's R2 is 0.736437\n",
      "Random Forest Model's MAE is 23.359890\n",
      "Random Forest Model's MSE is 1318.713790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SparseVector(10, {0: 0.0087, 1: 0.0017, 2: 0.0633, 3: 0.2595, 4: 0.5477, 5: 0.0496, 6: 0.0136, 7: 0.0444, 8: 0.0004, 9: 0.0111})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize Random Forest model\n",
    "rf1 = RandomForestRegressor(featuresCol=\"Features\",labelCol=\"Target\")\n",
    "# Fit the model\n",
    "rf1_model = rf1.fit(trainingData1)\n",
    "rf1_predictions = rf1_model.transform(testData1)\n",
    "evaluator = RegressionEvaluator(labelCol=\"Target\",predictionCol=\"prediction\")\n",
    "rf_rmse = evaluator.evaluate(rf1_predictions, {evaluator.metricName: \"rmse\"})\n",
    "print(\"Random Forest Model's RMSE is %f\"%rf_rmse)\n",
    "# r^2 metric\n",
    "rf_r2 = evaluator.evaluate(rf1_predictions, {evaluator.metricName: \"r2\"})\n",
    "print(\"Random Forest Model's R2 is %f\"%rf_r2)\n",
    "# mean absolute error \n",
    "rf_mae = evaluator.evaluate(rf1_predictions, {evaluator.metricName: \"mae\"})\n",
    "print(\"Random Forest Model's MAE is %f\"%rf_mae)\n",
    "# mean squared error\n",
    "rf_mse = evaluator.evaluate(rf1_predictions, {evaluator.metricName: \"mse\"})\n",
    "print(\"Random Forest Model's MSE is %f\"%rf_mse)\n",
    "featureImportances = rf1_model.featureImportances\n",
    "display(featureImportances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------------+\n",
      "|Features|RF's Feature Importance|\n",
      "+--------+-----------------------+\n",
      "|   month|                 0.0087|\n",
      "|    hour|                 0.0017|\n",
      "|     SO2|                 0.0633|\n",
      "|     NO2|                 0.2595|\n",
      "|      CO|                 0.5477|\n",
      "|      O3|                 0.0496|\n",
      "|    TEMP|                 0.0136|\n",
      "|    DEWP|                 0.0444|\n",
      "|    RAIN|                 4.0E-4|\n",
      "|    WSPM|                 0.0111|\n",
      "+--------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_featureImportance = spark.createDataFrame(\n",
    "                        [('month',0.0087),\n",
    "                         ('hour',0.0017),\n",
    "                         ('SO2',0.0633),\n",
    "                         ('NO2',0.2595),\n",
    "                         ('CO',0.5477),\n",
    "                         ('O3',0.0496),\n",
    "                         ('TEMP',0.0136),\n",
    "                         ('DEWP',0.0444),\n",
    "                         ('RAIN',0.0004),\n",
    "                         ('WSPM',0.0111)],\n",
    "                        [\"Features\",\"RF's Feature Importance\"])\n",
    "rf_featureImportance.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
